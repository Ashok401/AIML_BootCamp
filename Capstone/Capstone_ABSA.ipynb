{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTZNgvwKqt/Xcvec73DUmv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashok401/AIML_BootCamp/blob/main/Capstone/Capstone_ABSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aspect-based Sentiment Analysis\n",
        "\n",
        "- Explore the possibility of replacing expensive and slow LLMs with smaller, custom models. These models should be simple and scalable, while still maintaining acceptable quality.\n",
        "- Scaling the model to work on datasets containing 500 and 1000 reviews, which are currently in the top 100 reviews.\n",
        "- Observation: By employing Knowledge Distillation, we leverage an LLM (Teacher) to train a set of Logistic Regression ‚ÄúExpert‚Äù models (Students). These models attain an impressive 85%+ agreement with the LLM, all while incurring a 99.9% lower cost."
      ],
      "metadata": {
        "id": "Jz8JlodZy36N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data set : https://www.kaggle.com/datasets/mrmars1010/iphone-customer-reviews-nlp\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.multioutput import MultiOutputClassifier\n"
      ],
      "metadata": {
        "id": "6jKEW8EpTE1V",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iPhone Aspect-Based Sentiment Analysis (ABSA)**:\n",
        "Distilling LLM Intelligence into High-Performance Classical ML\n",
        "\n",
        "By using Knowledge Distillation, we utilize an LLM (Teacher) to train a suite of Logistic Regression \"Expert\" models (Students) that achieve 85%+ agreement with the LLM at 99.9% lower cost.\n",
        "\n",
        "üöÄ **The Problem & Solution**\n",
        "The Problem: LLMs (like GPT-4 or Gemini) are highly accurate but too slow and expensive for real-time analysis of millions of iPhone 14/15/16 reviews.\n",
        "\n",
        "The Solution: A \"Hybrid\" approach. We use the LLM to label a \"Gold Standard\" dataset of 1,000 reviews, then train a local, optimized TF-IDF + Logistic Regression pipeline to replicate that logic.\n",
        "\n",
        "üìä **Key Achievements**\n",
        "Aspect\tAccuracy (vs LLM)\tStatus\n",
        "\n",
        "Camera\t94%\tElite Performance\n",
        "\n",
        "Battery\t86%\tProduction Ready\n",
        "\n",
        "Performance\t84%\tProduction Ready\n",
        "\n",
        "Display\t79%\tStable Baseline\n",
        "\n",
        "Performance Gain: Inference latency reduced from ~1s/review (LLM) to <1ms/review (Local).\n",
        "\n",
        "\n",
        "üõ†Ô∏è **Technical Implementation**\n",
        "1. **Aspect Modeling**\n",
        "\n",
        "To ensure the model focuses on technical features, we use a structured aspect_map to filter reviews into specific categories:\n",
        "\n",
        "Battery: ['battery', 'charge', 'drain', 'backup', 'power']\n",
        "\n",
        "Camera: ['photo', 'video', 'lens', 'zoom', 'selfie', 'night mode']\n",
        "\n",
        "Display: ['screen', 'oled', 'brightness', 'refresh', 'hz', 'pixel']\n",
        "\n",
        "Performance: ['fast', 'lag', 'speed', 'processor', 'gaming', 'hang']\n",
        "\n",
        "2. **Model Optimization**\n",
        "\n",
        "The \"Student\" models were optimized using:\n",
        "\n",
        "Bigram Analysis (ngram_range=(1,2)): To understand negations like \"not fast.\"\n",
        "\n",
        "Class Balancing: Applied class_weight='balanced' to ensure the model catches negative complaints despite a positive data bias.\n",
        "\n",
        "Feature Capping: Limited to 1,000 features to prevent overfitting on specific iPhone 14/15 terminology, ensuring compatibility with future models (iPhone 16+)."
      ],
      "metadata": {
        "id": "0LNEbtnI6Ogl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the top 500 reviews  for aspect-based sentiment analysis.\n",
        "# Train the model with LLM labels and compare it to classical machine learning models to assess its performance compared to LLMs.\n",
        "# Conduct the experiment again with the top 1000 reviews to observe the impact on the model‚Äôs performance.\n",
        "\n",
        "datasets = [\n",
        "    {\n",
        "        \"name\": \"top500_reviews\",\n",
        "        \"raw\": \"top500_reviews.csv\",\n",
        "        \"labeled\": \"top500_reviews_with_llm_labels.csv\",\n",
        "        \"max_features\": 500\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"top1000_reviews\",\n",
        "        \"raw\": \"top1000_reviews.csv\",\n",
        "        \"labeled\": \"top1000_reviews_with_llm_labels.csv\",\n",
        "        \"max_features\": 1000\n",
        "    }\n",
        "]\n",
        "\n",
        "OPEN_AI_KEY = userdata.get('OPEN_AI_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = OPEN_AI_KEY\n",
        ")\n",
        "\n",
        "aspect_map = {\n",
        "    'llm_Battery': ['battery', 'charge', 'drain', 'backup', 'power'],\n",
        "    'llm_Display': ['screen', 'oled', 'brightness', 'refresh', 'hz', 'pixel'],\n",
        "    'llm_Camera': ['photo', 'video', 'lens', 'zoom', 'selfie', 'night mode'],\n",
        "    'llm_Performance': ['fast', 'lag', 'speed', 'processor', 'gaming', 'hang']\n",
        "}\n",
        "\n",
        "def get_llm_labels(review_text):\n",
        "    # Identify which aspects are actually in the text\n",
        "    text_lower = review_text.lower()\n",
        "    found_aspects = [a for a, keywords in aspect_map.items() if any(k in text_lower for k in keywords)]\n",
        "\n",
        "    if not found_aspects:\n",
        "        return {\"General\": 1 if \"good\" in text_lower else 0}\n",
        "\n",
        "    # Construct the prompt for ONLY the found aspects\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the sentiment for the following aspects in this phone review: {found_aspects}\n",
        "    Return ONLY a JSON object where 1 is positive and  0 is negative.\n",
        "        Review: \"{review_text}\"\n",
        "    Example Output: {{\"llm_Battery\": 1, \"llm_Camera\": 0}}\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        temperature=0\n",
        "    )\n",
        "    return json.loads(response.choices[0].message.content)\n",
        "\n",
        "for ds in datasets:\n",
        "  print(f\"Metrics for '{ds['name']}':\\n\")\n",
        "\n",
        "  csv_file = ds[\"labeled\"] if os.path.exists(ds[\"labeled\"]) else ds[\"raw\"]\n",
        "  df = pd.read_csv(csv_file)\n",
        "\n",
        "  llm_labels = list(aspect_map.keys())\n",
        "  llm_already_labled =  set(llm_labels).issubset(df.columns)\n",
        "\n",
        "  if llm_already_labled:\n",
        "    print(\"LLM labels are already available. Therefore, skipping the call to an LLM.\\n\")\n",
        "  else:\n",
        "    labels = df['review'].apply(lambda x: get_llm_labels(x))\n",
        "    labels_df = pd.json_normalize(labels)\n",
        "\n",
        "    df = pd.concat([df.reset_index(drop=True), labels_df.reset_index(drop=True)], axis=1)\n",
        "    df.to_csv(ds[\"labeled\"], index=False)\n",
        "\n",
        "  for col in llm_labels:\n",
        "    mask = df[col].notna()\n",
        "    X = df.loc[mask, 'review']\n",
        "    y = df.loc[mask, col].values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words = 'english', max_features=ds[\"max_features\"], ngram_range=(1, 2))),\n",
        "        ('clf', LogisticRegression(solver='liblinear', class_weight='balanced'))\n",
        "    ])\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nMetrics for '{col}':\\n\")\n",
        "    print(f\"classification_report:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"accuracy_score:\")\n",
        "    print(accuracy_score(y_test, y_pred))\n",
        "    print(f\"\\nconfusion_matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYbswBzJL6tR",
        "outputId": "7a9e05a4-93d6-431a-a0f8-5777383996ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for 'top500_reviews':\n",
            "\n",
            "LLM labels are already available. Therefore, skipping the call to an LLM.\n",
            "\n",
            "\n",
            "Metrics for 'llm_Battery':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.94      0.86        16\n",
            "         1.0       0.97      0.90      0.94        40\n",
            "\n",
            "    accuracy                           0.91        56\n",
            "   macro avg       0.88      0.92      0.90        56\n",
            "weighted avg       0.92      0.91      0.91        56\n",
            "\n",
            "accuracy_score:\n",
            "0.9107142857142857\n",
            "\n",
            "confusion_matrix:\n",
            "[[15  1]\n",
            " [ 4 36]]\n",
            "\n",
            "Metrics for 'llm_Display':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.85      0.73        13\n",
            "         1.0       0.88      0.70      0.78        20\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.76      0.77      0.76        33\n",
            "weighted avg       0.79      0.76      0.76        33\n",
            "\n",
            "accuracy_score:\n",
            "0.7575757575757576\n",
            "\n",
            "confusion_matrix:\n",
            "[[11  2]\n",
            " [ 6 14]]\n",
            "\n",
            "Metrics for 'llm_Camera':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         8\n",
            "         1.0       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00        26\n",
            "   macro avg       1.00      1.00      1.00        26\n",
            "weighted avg       1.00      1.00      1.00        26\n",
            "\n",
            "accuracy_score:\n",
            "1.0\n",
            "\n",
            "confusion_matrix:\n",
            "[[ 8  0]\n",
            " [ 0 18]]\n",
            "\n",
            "Metrics for 'llm_Performance':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.82      0.75        11\n",
            "         1.0       0.89      0.80      0.84        20\n",
            "\n",
            "    accuracy                           0.81        31\n",
            "   macro avg       0.79      0.81      0.80        31\n",
            "weighted avg       0.82      0.81      0.81        31\n",
            "\n",
            "accuracy_score:\n",
            "0.8064516129032258\n",
            "\n",
            "confusion_matrix:\n",
            "[[ 9  2]\n",
            " [ 4 16]]\n",
            "Metrics for 'top1000_reviews':\n",
            "\n",
            "LLM labels are already available. Therefore, skipping the call to an LLM.\n",
            "\n",
            "\n",
            "Metrics for 'llm_Battery':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.84      0.82        32\n",
            "         1.0       0.90      0.87      0.88        53\n",
            "\n",
            "    accuracy                           0.86        85\n",
            "   macro avg       0.85      0.86      0.85        85\n",
            "weighted avg       0.86      0.86      0.86        85\n",
            "\n",
            "accuracy_score:\n",
            "0.8588235294117647\n",
            "\n",
            "confusion_matrix:\n",
            "[[27  5]\n",
            " [ 7 46]]\n",
            "\n",
            "Metrics for 'llm_Display':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.92      0.84        25\n",
            "         1.0       0.85      0.61      0.71        18\n",
            "\n",
            "    accuracy                           0.79        43\n",
            "   macro avg       0.81      0.77      0.77        43\n",
            "weighted avg       0.80      0.79      0.78        43\n",
            "\n",
            "accuracy_score:\n",
            "0.7906976744186046\n",
            "\n",
            "confusion_matrix:\n",
            "[[23  2]\n",
            " [ 7 11]]\n",
            "\n",
            "Metrics for 'llm_Camera':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.88      0.93        16\n",
            "         1.0       0.90      1.00      0.95        19\n",
            "\n",
            "    accuracy                           0.94        35\n",
            "   macro avg       0.95      0.94      0.94        35\n",
            "weighted avg       0.95      0.94      0.94        35\n",
            "\n",
            "accuracy_score:\n",
            "0.9428571428571428\n",
            "\n",
            "confusion_matrix:\n",
            "[[14  2]\n",
            " [ 0 19]]\n",
            "\n",
            "Metrics for 'llm_Performance':\n",
            "\n",
            "classification_report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.72      0.79        18\n",
            "         1.0       0.83      0.93      0.88        27\n",
            "\n",
            "    accuracy                           0.84        45\n",
            "   macro avg       0.85      0.82      0.83        45\n",
            "weighted avg       0.85      0.84      0.84        45\n",
            "\n",
            "accuracy_score:\n",
            "0.8444444444444444\n",
            "\n",
            "confusion_matrix:\n",
            "[[13  5]\n",
            " [ 2 25]]\n"
          ]
        }
      ]
    }
  ]
}